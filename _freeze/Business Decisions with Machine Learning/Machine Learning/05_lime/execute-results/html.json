{
  "hash": "90c14fe5688d05c38a15488d68b15adc",
  "result": {
    "engine": "knitr",
    "markdown": "---\ntitle: \"05 LIME\"\ndate: \"2024-06-22\"\noutput:\n  html_document:\n    toc: true\n    toc_float: true\n    df_print: paged\n    collapsed: false\n    number_sections: true\n    toc_depth: 3\n    #code_folding: hide\n---\n\n\n\n::: {.cell}\n\n```{.r .cell-code}\nlibrary(h2o)\nlibrary(recipes)\nlibrary(readxl)\nlibrary(tidyverse)\nlibrary(tidyquant)\nlibrary(lime)\nlibrary(rsample)\n\nproduct_data <- read_csv(\"C:/Users/ranja/Documents/GitHub/ss24-bdml-1ranjan/Business Decisions with Machine Learning/Machine Learning/data/Business Decisions with Machine Learning/product_backorders.csv\")\nproduct_data2 <- product_data %>% \n  mutate(\n    product_backorder = went_on_backorder %>% str_to_lower() %>% str_detect(\"yes\") %>% as.numeric()\n  ) %>% \n  select(-c(went_on_backorder))\nglimpse(product_data)\n```\n\n::: {.cell-output .cell-output-stdout}\n\n```\nRows: 19,053\nColumns: 23\n$ sku               <dbl> 1113121, 1113268, 1113874, 1114222, 1114823, 1115453…\n$ national_inv      <dbl> 0, 0, 20, 0, 0, 55, -34, 4, 2, -7, 1, 2, 0, 0, 0, 0,…\n$ lead_time         <dbl> 8, 8, 2, 8, 12, 8, 8, 9, 8, 8, 8, 8, 12, 2, 12, 4, 2…\n$ in_transit_qty    <dbl> 1, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 1, 0…\n$ forecast_3_month  <dbl> 6, 2, 45, 9, 31, 216, 120, 43, 4, 56, 2, 5, 5, 54, 4…\n$ forecast_6_month  <dbl> 6, 3, 99, 14, 31, 360, 240, 67, 6, 96, 4, 9, 6, 72, …\n$ forecast_9_month  <dbl> 6, 4, 153, 21, 31, 492, 240, 115, 9, 112, 6, 13, 9, …\n$ sales_1_month     <dbl> 0, 1, 16, 5, 7, 30, 83, 5, 1, 13, 0, 1, 0, 0, 1, 0, …\n$ sales_3_month     <dbl> 4, 2, 42, 17, 15, 108, 122, 22, 5, 30, 2, 5, 4, 0, 3…\n$ sales_6_month     <dbl> 9, 3, 80, 36, 33, 275, 144, 40, 6, 56, 3, 8, 5, 0, 4…\n$ sales_9_month     <dbl> 12, 3, 111, 43, 47, 340, 165, 58, 9, 76, 4, 11, 6, 0…\n$ min_bank          <dbl> 0, 0, 10, 0, 2, 51, 33, 4, 2, 0, 0, 0, 3, 4, 0, 0, 0…\n$ potential_issue   <chr> \"No\", \"No\", \"No\", \"No\", \"No\", \"No\", \"No\", \"No\", \"No\"…\n$ pieces_past_due   <dbl> 1, 0, 0, 0, 3, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0…\n$ perf_6_month_avg  <dbl> 0.90, 0.96, 0.81, 0.96, 0.98, 0.00, 1.00, 0.69, 1.00…\n$ perf_12_month_avg <dbl> 0.89, 0.97, 0.88, 0.98, 0.98, 0.00, 0.97, 0.68, 0.95…\n$ local_bo_qty      <dbl> 0, 0, 0, 0, 0, 0, 34, 0, 0, 7, 0, 0, 0, 0, 0, 0, 0, …\n$ deck_risk         <chr> \"No\", \"No\", \"No\", \"No\", \"No\", \"No\", \"No\", \"No\", \"No\"…\n$ oe_constraint     <chr> \"No\", \"No\", \"No\", \"No\", \"No\", \"No\", \"No\", \"No\", \"No\"…\n$ ppap_risk         <chr> \"No\", \"No\", \"No\", \"No\", \"No\", \"Yes\", \"No\", \"No\", \"No…\n$ stop_auto_buy     <chr> \"Yes\", \"Yes\", \"Yes\", \"Yes\", \"Yes\", \"Yes\", \"Yes\", \"Ye…\n$ rev_stop          <chr> \"No\", \"No\", \"No\", \"No\", \"No\", \"No\", \"No\", \"No\", \"No\"…\n$ went_on_backorder <chr> \"Yes\", \"Yes\", \"Yes\", \"Yes\", \"Yes\", \"Yes\", \"Yes\", \"Ye…\n```\n\n\n:::\n\n```{.r .cell-code}\nsplit_obj<- initial_split(product_data2, prop = 0.75)\ntrain_tbl<- training(split_obj)\ntest_tbl<- testing(split_obj)\n\nrecipe_obj <- recipe(product_backorder ~., data = train_tbl) %>% \n  step_zv(all_predictors()) %>% \n  step_dummy(all_nominal(),-all_outcomes()) %>%\n  prep()\nsplit_obj<- initial_split(product_data2, prop = 0.75)\ntrain_tbl<- training(split_obj)\ntest_tbl<- testing(split_obj)\n\nh2o.init()\n```\n\n::: {.cell-output .cell-output-stdout}\n\n```\n\nH2O is not running yet, starting it now...\n\nNote:  In case of errors look at the following log files:\n    C:\\Users\\ranja\\AppData\\Local\\Temp\\RtmpMzkGQX\\fileb5c22667fda/h2o_ranjan_started_from_r.out\n    C:\\Users\\ranja\\AppData\\Local\\Temp\\RtmpMzkGQX\\fileb5c26eb2b60/h2o_ranjan_started_from_r.err\n\n\nStarting H2O JVM and connecting:  Connection successful!\n\nR is connected to the H2O cluster: \n    H2O cluster uptime:         3 seconds 322 milliseconds \n    H2O cluster timezone:       Europe/Berlin \n    H2O data parsing timezone:  UTC \n    H2O cluster version:        3.44.0.3 \n    H2O cluster version age:    6 months and 3 days \n    H2O cluster name:           H2O_started_from_R_ranjan_qmw453 \n    H2O cluster total nodes:    1 \n    H2O cluster total memory:   1.90 GB \n    H2O cluster total cores:    4 \n    H2O cluster allowed cores:  4 \n    H2O cluster healthy:        TRUE \n    H2O Connection ip:          localhost \n    H2O Connection port:        54321 \n    H2O Connection proxy:       NA \n    H2O Internal Security:      FALSE \n    R Version:                  R version 4.3.3 (2024-02-29 ucrt) \n```\n\n\n:::\n\n```{.r .cell-code}\nautoml_leader <- h2o.loadModel(\"C:/Users/ranja/Documents/GitHub/ss24-bdml-1ranjan/Business Decisions with Machine Learning/Machine Learning/StackedEnsemble_AllModels_AutoML_20220603_533865/StackedEnsemble_AllModels_3_AutoML_2_20240622_143225\")\nautoml_leader\n```\n\n::: {.cell-output .cell-output-stdout}\n\n```\nModel Details:\n==============\n\nH2ORegressionModel: stackedensemble\nModel ID:  StackedEnsemble_AllModels_3_AutoML_2_20240622_143225 \nModel Summary for Stacked Ensemble: \n                                         key            value\n1                          Stacking strategy cross_validation\n2       Number of base models (used / total)            14/38\n3           # GBM base models (used / total)            12/31\n4           # DRF base models (used / total)              1/2\n5  # DeepLearning base models (used / total)              1/4\n6           # GLM base models (used / total)              0/1\n7                      Metalearner algorithm              GLM\n8         Metalearner fold assignment scheme           Random\n9                         Metalearner nfolds                5\n10                   Metalearner fold_column               NA\n11        Custom metalearner hyperparameters             None\n\n\nH2ORegressionMetrics: stackedensemble\n** Reported on training data. **\n\nMSE:  0.01675047\nRMSE:  0.1294236\nMAE:  0.06574773\nRMSLE:  0.09208955\nMean Residual Deviance :  0.01675047\n\n\nH2ORegressionMetrics: stackedensemble\n** Reported on validation data. **\n\nMSE:  0.05175661\nRMSE:  0.2275008\nMAE:  0.1174427\nRMSLE:  0.16054\nMean Residual Deviance :  0.05175661\n\n\nH2ORegressionMetrics: stackedensemble\n** Reported on cross-validation data. **\n** 5-fold cross-validation on training data (Metrics computed for combined holdout predictions) **\n\nMSE:  0.05073205\nRMSE:  0.2252378\nMAE:  0.115092\nRMSLE:  0.158539\nMean Residual Deviance :  0.05073205\n\n\nCross-Validation Metrics Summary: \n                             mean        sd cv_1_valid cv_2_valid cv_3_valid\nmae                      0.115008  0.003752   0.117344   0.113491   0.117467\nmean_residual_deviance   0.050652  0.002845   0.051887   0.050212   0.052512\nmse                      0.050652  0.002845   0.051887   0.050212   0.052512\nnull_deviance          223.098720 12.645634 221.311770 236.129180 220.070900\nr2                       0.511638  0.022957   0.502487   0.532869   0.475815\nresidual_deviance      108.839264  7.016921 110.104950 110.265660 115.316900\nrmse                     0.224987  0.006413   0.227788   0.224080   0.229156\nrmsle                    0.158240  0.004583   0.160236   0.157701   0.161608\n                       cv_4_valid cv_5_valid\nmae                      0.109060   0.117676\nmean_residual_deviance   0.045884   0.052763\nmse                      0.045884   0.052763\nnull_deviance          204.435030 233.546720\nr2                       0.525557   0.521463\nresidual_deviance       96.861490 111.647320\nrmse                     0.214206   0.229703\nrmsle                    0.150499   0.161154\n```\n\n\n:::\n\n```{.r .cell-code}\npredictions_tbl <- automl_leader %>% \n  h2o.predict(newdata = as.h2o(test_tbl)) %>%\n  as.tibble() %>%\n  bind_cols(\n    test_tbl %>%\n      select(everything())\n  )\n```\n\n::: {.cell-output .cell-output-stdout}\n\n```\n\n  |                                                                            \n  |                                                                      |   0%\n  |                                                                            \n  |======================================================================| 100%\n\n  |                                                                            \n  |                                                                      |   0%\n  |                                                                            \n  |======================================================================| 100%\n```\n\n\n:::\n\n```{.r .cell-code}\npredictions_tbl\n```\n\n::: {.cell-output .cell-output-stdout}\n\n```\n# A tibble: 4,764 × 24\n   predict     sku national_inv lead_time in_transit_qty forecast_3_month\n     <dbl>   <dbl>        <dbl>     <dbl>          <dbl>            <dbl>\n 1  0.522  1113268            0         8              0                2\n 2  1.00   1114222            0         8              0                9\n 3  0.0942 1115453           55         8              0              216\n 4  0.918  1116446            4         9              0               43\n 5  0.748  1118248            0        12              0                5\n 6  0.550  1124305           11         2              0                6\n 7  0.428  1125134           11         2              0                0\n 8  0.148  1126177            9         8              0                6\n 9  0.335  1127720          150         8              0              325\n10  0.920  1132099           11         2             10               27\n# ℹ 4,754 more rows\n# ℹ 18 more variables: forecast_6_month <dbl>, forecast_9_month <dbl>,\n#   sales_1_month <dbl>, sales_3_month <dbl>, sales_6_month <dbl>,\n#   sales_9_month <dbl>, min_bank <dbl>, potential_issue <chr>,\n#   pieces_past_due <dbl>, perf_6_month_avg <dbl>, perf_12_month_avg <dbl>,\n#   local_bo_qty <dbl>, deck_risk <chr>, oe_constraint <chr>, ppap_risk <chr>,\n#   stop_auto_buy <chr>, rev_stop <chr>, product_backorder <dbl>\n```\n\n\n:::\n\n```{.r .cell-code}\nsummary(train_tbl)\n```\n\n::: {.cell-output .cell-output-stdout}\n\n```\n      sku           national_inv        lead_time      in_transit_qty     \n Min.   :1111620   Min.   : -1440.0   Min.   : 0.000   Min.   :     0.00  \n 1st Qu.:1512546   1st Qu.:     3.0   1st Qu.: 4.000   1st Qu.:     0.00  \n Median :1919777   Median :    11.0   Median : 8.000   Median :     0.00  \n Mean   :2055670   Mean   :   382.2   Mean   : 7.713   Mean   :    51.91  \n 3rd Qu.:2821553   3rd Qu.:    64.0   3rd Qu.: 8.000   3rd Qu.:     0.00  \n Max.   :3284775   Max.   :730722.0   Max.   :52.000   Max.   :170920.00  \n                                      NA's   :807                         \n forecast_3_month forecast_6_month   forecast_9_month    sales_1_month   \n Min.   :     0   Min.   :     0.0   Min.   :      0.0   Min.   :     0  \n 1st Qu.:     0   1st Qu.:     0.0   1st Qu.:      0.0   1st Qu.:     0  \n Median :     0   Median :     0.0   Median :      0.0   Median :     0  \n Mean   :   205   Mean   :   387.9   Mean   :    559.2   Mean   :    62  \n 3rd Qu.:     9   3rd Qu.:    20.0   3rd Qu.:     30.0   3rd Qu.:     5  \n Max.   :479808   Max.   :967776.0   Max.   :1418208.0   Max.   :186451  \n                                                                         \n sales_3_month      sales_6_month       sales_9_month          min_bank       \n Min.   :     0.0   Min.   :      0.0   Min.   :      0.0   Min.   :    0.00  \n 1st Qu.:     0.0   1st Qu.:      0.0   1st Qu.:      0.0   1st Qu.:    0.00  \n Median :     2.0   Median :      3.0   Median :      5.0   Median :    0.00  \n Mean   :   188.5   Mean   :    371.6   Mean   :    563.3   Mean   :   53.52  \n 3rd Qu.:    16.0   3rd Qu.:     32.0   3rd Qu.:     48.0   3rd Qu.:    3.00  \n Max.   :550609.0   Max.   :1136154.0   Max.   :1759152.0   Max.   :85584.00  \n                                                                              \n potential_issue    pieces_past_due     perf_6_month_avg  perf_12_month_avg\n Length:14289       Min.   :    0.000   Min.   :-99.000   Min.   :-99.00   \n Class :character   1st Qu.:    0.000   1st Qu.:  0.630   1st Qu.:  0.66   \n Mode  :character   Median :    0.000   Median :  0.820   Median :  0.80   \n                    Mean   :    2.501   Mean   : -6.556   Mean   : -6.08   \n                    3rd Qu.:    0.000   3rd Qu.:  0.970   3rd Qu.:  0.95   \n                    Max.   :13824.000   Max.   :  1.000   Max.   :  1.00   \n                                                                           \n  local_bo_qty        deck_risk         oe_constraint       ppap_risk        \n Min.   :   0.0000   Length:14289       Length:14289       Length:14289      \n 1st Qu.:   0.0000   Class :character   Class :character   Class :character  \n Median :   0.0000   Mode  :character   Mode  :character   Mode  :character  \n Mean   :   0.7788                                                           \n 3rd Qu.:   0.0000                                                           \n Max.   :1440.0000                                                           \n                                                                             \n stop_auto_buy        rev_stop         product_backorder\n Length:14289       Length:14289       Min.   :0.0000   \n Class :character   Class :character   1st Qu.:0.0000   \n Mode  :character   Mode  :character   Median :0.0000   \n                                       Mean   :0.1218   \n                                       3rd Qu.:0.0000   \n                                       Max.   :1.0000   \n                                                        \n```\n\n\n:::\n\n```{.r .cell-code}\n## Original plot_features()\n\n# explanation %>% \n#   as.tibble()\n#   \n# case_1 <- explanation %>%\n#     filter(case == 1)\n# \n# case_1 %>%\n#     plot_features()\n# You will need at least the layers geom_col() and coord_flip().\nexplainer <- train_tbl %>%\n  select(-product_backorder) %>%\n  lime(\n    model           = automl_leader,\n    bin_continuous  = TRUE,\n    n_bins          = 4,\n    quantile_bins   = TRUE\n  )\nexplainer\n```\n\n::: {.cell-output .cell-output-stdout}\n\n```\n$model\nModel Details:\n==============\n\nH2ORegressionModel: stackedensemble\nModel ID:  StackedEnsemble_AllModels_3_AutoML_2_20240622_143225 \nModel Summary for Stacked Ensemble: \n                                         key            value\n1                          Stacking strategy cross_validation\n2       Number of base models (used / total)            14/38\n3           # GBM base models (used / total)            12/31\n4           # DRF base models (used / total)              1/2\n5  # DeepLearning base models (used / total)              1/4\n6           # GLM base models (used / total)              0/1\n7                      Metalearner algorithm              GLM\n8         Metalearner fold assignment scheme           Random\n9                         Metalearner nfolds                5\n10                   Metalearner fold_column               NA\n11        Custom metalearner hyperparameters             None\n\n\nH2ORegressionMetrics: stackedensemble\n** Reported on training data. **\n\nMSE:  0.01675047\nRMSE:  0.1294236\nMAE:  0.06574773\nRMSLE:  0.09208955\nMean Residual Deviance :  0.01675047\n\n\nH2ORegressionMetrics: stackedensemble\n** Reported on validation data. **\n\nMSE:  0.05175661\nRMSE:  0.2275008\nMAE:  0.1174427\nRMSLE:  0.16054\nMean Residual Deviance :  0.05175661\n\n\nH2ORegressionMetrics: stackedensemble\n** Reported on cross-validation data. **\n** 5-fold cross-validation on training data (Metrics computed for combined holdout predictions) **\n\nMSE:  0.05073205\nRMSE:  0.2252378\nMAE:  0.115092\nRMSLE:  0.158539\nMean Residual Deviance :  0.05073205\n\n\nCross-Validation Metrics Summary: \n                             mean        sd cv_1_valid cv_2_valid cv_3_valid\nmae                      0.115008  0.003752   0.117344   0.113491   0.117467\nmean_residual_deviance   0.050652  0.002845   0.051887   0.050212   0.052512\nmse                      0.050652  0.002845   0.051887   0.050212   0.052512\nnull_deviance          223.098720 12.645634 221.311770 236.129180 220.070900\nr2                       0.511638  0.022957   0.502487   0.532869   0.475815\nresidual_deviance      108.839264  7.016921 110.104950 110.265660 115.316900\nrmse                     0.224987  0.006413   0.227788   0.224080   0.229156\nrmsle                    0.158240  0.004583   0.160236   0.157701   0.161608\n                       cv_4_valid cv_5_valid\nmae                      0.109060   0.117676\nmean_residual_deviance   0.045884   0.052763\nmse                      0.045884   0.052763\nnull_deviance          204.435030 233.546720\nr2                       0.525557   0.521463\nresidual_deviance       96.861490 111.647320\nrmse                     0.214206   0.229703\nrmsle                    0.150499   0.161154\n\n$preprocess\nfunction (x) \nx\n<bytecode: 0x000001c1546a0f08>\n<environment: 0x000001c154695538>\n\n$bin_continuous\n[1] TRUE\n\n$n_bins\n[1] 4\n\n$quantile_bins\n[1] TRUE\n\n$use_density\n[1] TRUE\n\n$feature_type\n              sku      national_inv         lead_time    in_transit_qty \n        \"numeric\"         \"numeric\"         \"numeric\"         \"numeric\" \n forecast_3_month  forecast_6_month  forecast_9_month     sales_1_month \n        \"numeric\"         \"numeric\"         \"numeric\"         \"numeric\" \n    sales_3_month     sales_6_month     sales_9_month          min_bank \n        \"numeric\"         \"numeric\"         \"numeric\"         \"numeric\" \n  potential_issue   pieces_past_due  perf_6_month_avg perf_12_month_avg \n      \"character\"         \"numeric\"         \"numeric\"         \"numeric\" \n     local_bo_qty         deck_risk     oe_constraint         ppap_risk \n        \"numeric\"       \"character\"       \"character\"       \"character\" \n    stop_auto_buy          rev_stop \n      \"character\"       \"character\" \n\n$bin_cuts\n$bin_cuts$sku\n     0%     25%     50%     75%    100% \n1111620 1512546 1919777 2821553 3284775 \n\n$bin_cuts$national_inv\n    0%    25%    50%    75%   100% \n -1440      3     11     64 730722 \n\n$bin_cuts$lead_time\n  0%  25%  50% 100% \n   0    4    8   52 \n\n$bin_cuts$in_transit_qty\n[1]      0  42730  85460 128190 170920\n\n$bin_cuts$forecast_3_month\n    0%    75%   100% \n     0      9 479808 \n\n$bin_cuts$forecast_6_month\n    0%    75%   100% \n     0     20 967776 \n\n$bin_cuts$forecast_9_month\n     0%     75%    100% \n      0      30 1418208 \n\n$bin_cuts$sales_1_month\n    0%    75%   100% \n     0      5 186451 \n\n$bin_cuts$sales_3_month\n    0%    50%    75%   100% \n     0      2     16 550609 \n\n$bin_cuts$sales_6_month\n     0%     50%     75%    100% \n      0       3      32 1136154 \n\n$bin_cuts$sales_9_month\n     0%     50%     75%    100% \n      0       5      48 1759152 \n\n$bin_cuts$min_bank\n   0%   75%  100% \n    0     3 85584 \n\n$bin_cuts$potential_issue\nNULL\n\n$bin_cuts$pieces_past_due\n[1]     0  3456  6912 10368 13824\n\n$bin_cuts$perf_6_month_avg\n    0%    25%    50%    75%   100% \n-99.00   0.63   0.82   0.97   1.00 \n\n$bin_cuts$perf_12_month_avg\n    0%    25%    50%    75%   100% \n-99.00   0.66   0.80   0.95   1.00 \n\n$bin_cuts$local_bo_qty\n[1]    0  360  720 1080 1440\n\n$bin_cuts$deck_risk\nNULL\n\n$bin_cuts$oe_constraint\nNULL\n\n$bin_cuts$ppap_risk\nNULL\n\n$bin_cuts$stop_auto_buy\nNULL\n\n$bin_cuts$rev_stop\nNULL\n\n\n$feature_distribution\n$feature_distribution$sku\n\n        1         2         3         4 \n0.2500525 0.2499825 0.2499825 0.2499825 \n\n$feature_distribution$national_inv\n\n        1         2         3         4 \n0.2759465 0.2252082 0.2489327 0.2499125 \n\n$feature_distribution$lead_time\n\n        1         2         3 \n0.2979215 0.4171041 0.2284974 \n\n$feature_distribution$in_transit_qty\n\n           1            2            4 \n0.9997900483 0.0001399678 0.0000699839 \n\n$feature_distribution$forecast_3_month\n\n        1         2 \n0.7507173 0.2492827 \n\n$feature_distribution$forecast_6_month\n\n        1         2 \n0.7540766 0.2459234 \n\n$feature_distribution$forecast_9_month\n\n        1         2 \n0.7525369 0.2474631 \n\n$feature_distribution$sales_1_month\n\n        1         2 \n0.7589754 0.2410246 \n\n$feature_distribution$sales_3_month\n\n        1         2         3 \n0.5499335 0.2021835 0.2478830 \n\n$feature_distribution$sales_6_month\n\n        1         2         3 \n0.5068234 0.2441039 0.2490727 \n\n$feature_distribution$sales_9_month\n\n        1         2         3 \n0.5122122 0.2397649 0.2480230 \n\n$feature_distribution$min_bank\n\n        1         2 \n0.7543565 0.2456435 \n\n$feature_distribution$potential_issue\n\n         No         Yes \n0.998810274 0.001189726 \n\n$feature_distribution$pieces_past_due\n\n          1           4 \n9.99930e-01 6.99839e-05 \n\n$feature_distribution$perf_6_month_avg\n\n        1         2         3         4 \n0.2609000 0.2557912 0.2670586 0.2162503 \n\n$feature_distribution$perf_12_month_avg\n\n        1         2         3         4 \n0.2829449 0.2231787 0.2607600 0.2331164 \n\n$feature_distribution$local_bo_qty\n\n           1            2            4 \n0.9995800966 0.0002799356 0.0001399678 \n\n$feature_distribution$deck_risk\n\n       No       Yes \n0.7809504 0.2190496 \n\n$feature_distribution$oe_constraint\n\n          No          Yes \n0.9996500805 0.0003499195 \n\n$feature_distribution$ppap_risk\n\n       No       Yes \n0.8759185 0.1240815 \n\n$feature_distribution$stop_auto_buy\n\n        No        Yes \n0.03422213 0.96577787 \n\n$feature_distribution$rev_stop\n\n          No          Yes \n0.9995800966 0.0004199034 \n\n\nattr(,\"class\")\n[1] \"data_frame_explainer\" \"explainer\"            \"list\"                \n```\n\n\n:::\n\n```{.r .cell-code}\nexplanation <- test_tbl %>%\n  slice(1) %>%\n  select(-product_backorder) %>%\n  lime::explain(\n    \n    # Pass our explainer object\n    explainer = explainer,\n    # Because it is a binary classification model: 1\n    n_labels   = 1,\n    # number of features to be returned\n    n_features = 8,\n    # number of localized linear models\n    n_permutations = 5000,\n    # Let's start with 1\n    kernel_width   = 1\n  )\n```\n\n::: {.cell-output .cell-output-stdout}\n\n```\n\n  |                                                                            \n  |                                                                      |   0%\n  |                                                                            \n  |======================================================================| 100%\n\n  |                                                                            \n  |                                                                      |   0%\n  |                                                                            \n  |======================================================================| 100%\n```\n\n\n:::\n\n```{.r .cell-code}\nexplanation\n```\n\n::: {.cell-output .cell-output-stdout}\n\n```\n# A tibble: 8 × 11\n  model_type case  model_r2 model_intercept model_prediction feature         \n  <chr>      <chr>    <dbl>           <dbl>            <dbl> <chr>           \n1 regression 1        0.319           0.226            0.557 in_transit_qty  \n2 regression 1        0.319           0.226            0.557 national_inv    \n3 regression 1        0.319           0.226            0.557 potential_issue \n4 regression 1        0.319           0.226            0.557 forecast_3_month\n5 regression 1        0.319           0.226            0.557 sku             \n6 regression 1        0.319           0.226            0.557 local_bo_qty    \n7 regression 1        0.319           0.226            0.557 forecast_9_month\n8 regression 1        0.319           0.226            0.557 sales_1_month   \n# ℹ 5 more variables: feature_value <chr>, feature_weight <dbl>,\n#   feature_desc <chr>, data <list>, prediction <dbl>\n```\n\n\n:::\n\n```{.r .cell-code}\ng <- plot_features(explanation = explanation, ncol = 1, cases = 1)\ng\n```\n\n::: {.cell-output-display}\n![](05_lime_files/figure-html/unnamed-chunk-1-1.png){width=672}\n:::\n\n```{.r .cell-code}\n## Bonus Objectives:\n\nexplanation_multi <- test_tbl %>%\n  slice(1:20) %>%\n  select(-product_backorder) %>%\n  lime::explain(\n    explainer = explainer,\n    n_labels   = 1,\n    n_features = 8,\n    n_permutations = 5000,\n    kernel_width   = 0.5\n  )\n```\n\n::: {.cell-output .cell-output-stdout}\n\n```\n\n  |                                                                            \n  |                                                                      |   0%\n  |                                                                            \n  |======================================================================| 100%\n\n  |                                                                            \n  |                                                                      |   0%\n  |                                                                            \n  |======================================================================| 100%\n```\n\n\n:::\n\n```{.r .cell-code}\nexplanation_multi %>%\n  as.tibble()\n```\n\n::: {.cell-output .cell-output-stdout}\n\n```\n# A tibble: 160 × 11\n   model_type case  model_r2 model_intercept model_prediction feature         \n   <chr>      <chr>    <dbl>           <dbl>            <dbl> <chr>           \n 1 regression 1        0.338           0.355            0.565 in_transit_qty  \n 2 regression 1        0.338           0.355            0.565 national_inv    \n 3 regression 1        0.338           0.355            0.565 local_bo_qty    \n 4 regression 1        0.338           0.355            0.565 forecast_3_month\n 5 regression 1        0.338           0.355            0.565 sku             \n 6 regression 1        0.338           0.355            0.565 potential_issue \n 7 regression 1        0.338           0.355            0.565 forecast_9_month\n 8 regression 1        0.338           0.355            0.565 sales_1_month   \n 9 regression 2        0.306           0.276            0.589 pieces_past_due \n10 regression 2        0.306           0.276            0.589 national_inv    \n# ℹ 150 more rows\n# ℹ 5 more variables: feature_value <chr>, feature_weight <dbl>,\n#   feature_desc <chr>, data <list>, prediction <dbl>\n```\n\n\n:::\n\n```{.r .cell-code}\nplot_explanations(explanation_multi)\n```\n\n::: {.cell-output-display}\n![](05_lime_files/figure-html/unnamed-chunk-1-2.png){width=672}\n:::\n\n```{.r .cell-code}\n# Part 2: Recreate plot_explanations():\n## Customized plot_features()\n\ntheme_lime <- function(...) {\n  theme_minimal() +\n    theme(\n      strip.text = element_text(face = 'bold', size = 9),\n      plot.margin = margin(15, 15, 15, 15),\n      legend.background = element_blank(),\n      legend.key = element_blank(),\n      panel.grid.major.y = element_blank(),\n      panel.grid.minor.y = element_blank(),\n      axis.ticks = element_blank(),\n      legend.position = 'bottom',\n      panel.spacing.y = unit(15, 'pt'),\n      strip.text.x = element_text(margin = margin(t = 2, b = 2), hjust = 0),\n      axis.title.y = element_text(margin = margin(r = 10)),\n      axis.title.x = element_text(margin = margin(t = 10)),\n      panel.background = element_rect(fill   = \"transparent\"),\n      panel.border     = element_rect(color = \"black\", fill = NA, size = 0.5),\n      panel.grid.major = element_line(color = \"grey\", size = 0.333),\n      ...\n    )\n}\n\nplot_explanations_customized <- function(explanation, ...) {\n  num_cases <- unique(suppressWarnings(as.numeric(explanation$case)))\n  if (!anyNA(num_cases)) {\n    explanation$case <- factor(explanation$case, levels = as.character(sort(num_cases)))\n  }\n  explanation$feature_desc <- factor(\n    explanation$feature_desc,\n    levels = rev(unique(explanation$feature_desc[order(explanation$feature, explanation$feature_value)]))\n  )\n  \n  \n  p <- ggplot(explanation, aes_(~case, ~feature_desc),show.legend=TRUE) +\n    geom_tile(aes_(fill = ~feature_weight)) +\n    scale_x_discrete('Case', expand = c(0, 0)) +\n    scale_y_discrete('Feature', expand = c(0, 0)) +\n    scale_fill_gradient2('Feature\\nweight', low = 'firebrick', mid = '#f7f7f7', high = 'steelblue') +\n    theme_lime() +\n    theme(panel.border = element_rect(fill = NA, colour = 'grey60', size = 1),\n          panel.grid = element_blank(),\n          legend.position = 'right',\n          axis.text.x = element_text(angle = 45, hjust = 1, vjust = 1))\n  if (is.null(explanation$label)) {\n    p\n  } else {\n    p + facet_wrap(~label, ...)\n  }\n}\n\n\n\nplot_explanations_customized(explanation = explanation, ncol = 1, cases = 1)\n```\n\n::: {.cell-output-display}\n![](05_lime_files/figure-html/unnamed-chunk-1-3.png){width=672}\n:::\n\n```{.r .cell-code}\nplot_explanations_customized(explanation_multi)\n```\n\n::: {.cell-output-display}\n![](05_lime_files/figure-html/unnamed-chunk-1-4.png){width=672}\n:::\n:::",
    "supporting": [],
    "filters": [
      "rmarkdown/pagebreak.lua"
    ],
    "includes": {},
    "engineDependencies": {},
    "preserve": {},
    "postProcess": true
  }
}